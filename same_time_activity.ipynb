{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bce4bf-b920-49b0-ae98-8f63dd2b2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load the dataset\n",
    "df_visits = pd.read_csv('df_melt_sorted_fin.csv')\n",
    "\n",
    "# Ensure that VISIT_IDs are unique before sampling\n",
    "unique_visit_ids = df_visits['VISIT_ID'].unique()\n",
    "\n",
    "# Randomly select 10 VISIT_IDs\n",
    "random_visit_ids = random.sample(list(unique_visit_ids), 10)\n",
    "\n",
    "# Extract the activity sequence for each of these VISIT_IDs\n",
    "for visit_id in random_visit_ids:\n",
    "    visit_data = df_visits[df_visits['VISIT_ID'] == visit_id]\n",
    "    activities_sequence = visit_data[['Activity', 'Start_Time']].sort_values('Start_Time')\n",
    "    print(f\"Visit ID: {visit_id}\\n\", activities_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36fa93-a888-46df-a5a3-fe55b3fa6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits['Activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad40667-987d-410d-a6a7-6d2ef62aa864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by 'VISIT_ID' and 'Start_Time', and count the number of activities for each group\n",
    "grouped = df_visits.groupby(['VISIT_ID', 'Start_Time'])['Activity'].count()\n",
    "\n",
    "# Filter groups where the count of activities is 2 or more\n",
    "same_time_activities = grouped[grouped >= 2]\n",
    "\n",
    "# Get the indices of the original DataFrame where the combinations of 'VISIT_ID' and 'Start_Time' match\n",
    "# those with 2 or more activities\n",
    "valid_indices = same_time_activities.index\n",
    "\n",
    "# Filter the original DataFrame to get only the rows with the required 'VISIT_ID' and 'Start_Time'\n",
    "result = df_visits[df_visits.set_index(['VISIT_ID', 'Start_Time']).index.isin(valid_indices)].reset_index(drop=True)\n",
    "\n",
    "result.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf0e4a-e6cd-43e6-8910-b3767b076e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define allowed combinations of activities\n",
    "allowed_combinations = [\n",
    "    {'Assessment', 'Triage'}, \n",
    "    {'Triage', 'Providing service'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7cbb51-7c77-4c41-ac74-d663933567cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'VISIT_ID' and 'Start_Time', without reducing to a count first\n",
    "grouped = df_visits.groupby(['VISIT_ID', 'Start_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398200e4-b9ec-445a-bc41-302dca680747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to collect the indices of rows that do not meet the condition\n",
    "invalid_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d31492-35c6-4e6a-ba54-37286bf547f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each group\n",
    "for (visit_id, start_time), group in grouped:\n",
    "    # Create a set of activities present in the current group\n",
    "    activity_set = set(group['Activity'])\n",
    "    \n",
    "    # Check if the activity set does not match any of the allowed combinations\n",
    "    if not any(activity_set == allowed_set for allowed_set in allowed_combinations):\n",
    "        # If the group is invalid and the group size is more than 1 (implying multiple activities at the same time),\n",
    "        # append the indices of the invalid rows to our list\n",
    "        if len(activity_set) > 1:\n",
    "            invalid_indices.extend(group.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e4987-6a27-4b76-98d7-d41dee008f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the collected indices to remove the invalid rows from the original DataFrame\n",
    "filtered_df = df_visits.drop(invalid_indices)\n",
    "\n",
    "\n",
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ba31f-55bc-4597-9322-4d7023fc45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db831ea-1ae0-47c8-9a30-243dc533d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5e258-840c-410a-8861-42bd97b2ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_visits = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be719a85-c52a-48ac-8f02-42a427460db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original DataFrame size: {df_visits.shape[0]}\")\n",
    "print(f\"Cleaned DataFrame size: {clean_df_visits.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cced7a5-b4d7-4857-be78-bf548b49a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_visits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282b3f8-df36-4094-b3e9-4a69f3d4a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_visits['Activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07888940-40a8-4469-8155-6ddaf70258c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_visits_dur is your DataFrame\n",
    "# Ensure 'Start_Time' is converted to datetime\n",
    "clean_df_visits['Start_Time'] = pd.to_datetime(clean_df_visits['Start_Time'])\n",
    "\n",
    "# Group by 'VISIT_ID' and calculate the earliest and latest 'Start_Time'\n",
    "time_stats = clean_df_visits.groupby('VISIT_ID')['Start_Time'].agg(['min', 'max']).reset_index()\n",
    "time_stats.rename(columns={'min': 'Earliest_Time', 'max': 'End_Time'}, inplace=True)\n",
    "\n",
    "# Calculate duration for each group\n",
    "# The subtraction here will automatically yield a Timedelta since 'min' and 'max' are datetime objects\n",
    "time_stats['Duration'] = time_stats['End_Time'] - time_stats['Earliest_Time']\n",
    "\n",
    "# Merge the 'Earliest_Time', 'End_Time', and 'Duration' back into the original DataFrame\n",
    "clean_df_visits_dur = clean_df_visits.merge(time_stats[['VISIT_ID', 'Earliest_Time', 'End_Time', 'Duration']], on='VISIT_ID', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ade9e3-2018-4588-ad00-66e6f6fa1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_visits_dur.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df615306-4994-41da-a87b-39909536e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The DataFrame now includes 'End_Time' and 'Duration' for each visit\n",
    "clean_df_visits_dur.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f5c8e-81fd-49b0-827d-366d04844923",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_visits_dur['FACILITY_NAME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910390e-b5cb-401a-87fa-fb2c027bd758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of facilities to keep\n",
    "facilities_to_keep = [\n",
    "    'Health Sciences Centre - St. Johns',\n",
    "    'St. Clares Mercy Hospital - St. Johns',\n",
    "    'Dr. G.B. Cross Memorial Hospital - Clarenville',\n",
    "    'Carbonear General Hospital - Carbonear'\n",
    "]\n",
    "\n",
    "# Filter the DataFrame to include only the rows where the FACILITY_NAME is in the facilities_to_keep list\n",
    "df_visits_dur_filtered = clean_df_visits_dur[clean_df_visits_dur['FACILITY_NAME'].isin(facilities_to_keep)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2991a-e88e-4c5c-a44d-7ed3c579e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequences of activities to keep\n",
    "sequence1 = ['Triage', 'Providing service', 'Assessment', 'Patient departed']\n",
    "sequence2 = ['Triage', 'Providing service', 'Patient departed']\n",
    "sequence3 = ['Triage', 'Providing service', 'Assessment', 'Making admit decision', 'Admitting patient', 'Patient departed', 'Patient discharge']\n",
    "\n",
    "# Function to check if the visit activities match one of the sequences\n",
    "def check_sequence(group):\n",
    "    activities = group.sort_values('Start_Time')['Activity'].tolist()  # Get the sorted list of activities\n",
    "    return activities == sequence1 or activities == sequence2 or activities == sequence3\n",
    "\n",
    "# Group by VISIT_ID and filter\n",
    "filtered_visits = clean_df_visits_dur.groupby('VISIT_ID').filter(check_sequence)\n",
    "\n",
    "# Count unique VISIT_IDs in the filtered dataset\n",
    "unique_visit_count = filtered_visits['VISIT_ID'].nunique()\n",
    "\n",
    "unique_visit_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f1421-912d-4e44-8283-424c9ef1ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Step 1: Sort by VISIT_ID and Start_Time to ensure the sequence\n",
    "sorted_visits = filtered_visits.sort_values(by=['VISIT_ID', 'Start_Time'])\n",
    "\n",
    "# Calculate the actual duration for each activity \n",
    "# calculated as difference between Start_Time and End_Time\n",
    "sorted_visits['Activity_Duration'] = (sorted_visits['End_Time'] - sorted_visits['Start_Time']).dt.total_seconds() / 3600.0\n",
    "\n",
    "# Calculate the transition duration between the end of one activity and the start of the next\n",
    "sorted_visits['Next_Start_Time'] = sorted_visits.groupby('VISIT_ID')['Start_Time'].shift(-1)\n",
    "sorted_visits['Step_Duration'] = (sorted_visits['Next_Start_Time'] - sorted_visits['End_Time']).dt.total_seconds() / 3600.0\n",
    "\n",
    "#  calculate the standard deviation for each Activity's own duration\n",
    "std_activity_durations = sorted_visits.groupby('Activity')['Activity_Duration'].std()\n",
    "\n",
    "mean_activity_durations = sorted_visits.groupby('Activity')['Activity_Duration'].mean()\n",
    "\n",
    "#  the standard deviation for the transitions between activities\n",
    "std_step_durations = sorted_visits.groupby('Activity')['Step_Duration'].std()\n",
    "\n",
    "std_activity_durations, mean_activity_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b0fc8a-54cd-4458-ad8e-77cf46ddca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits_dur_filtered['Activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3bd63-7395-4a9b-84e7-c0f1df4edf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequences of activities to keep\n",
    "sequence1 = ['Triage', 'Providing service', 'Assessment', 'Patient departed']\n",
    "sequence2 = ['Triage', 'Providing service', 'Patient departed']\n",
    "\n",
    "# Function to check if the visit activities match one of the sequences\n",
    "def check_sequence(group):\n",
    "    activities = group.sort_values('Start_Time')['Activity'].tolist()  # Get the sorted list of activities\n",
    "    return activities == sequence1 or activities == sequence2\n",
    "\n",
    "# Group by VISIT_ID and filter\n",
    "filtered_visits = df_visits_dur_filtered.groupby('VISIT_ID').filter(check_sequence)\n",
    "\n",
    "filtered_visits['VISIT_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868df455-d4e4-43d6-9659-29a057620403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df_visits_dur' is your DataFrame and 'Duration' is already calculated as timedelta\n",
    "# Convert 'Duration' to a suitable numeric form for calculation, such as seconds or hours\n",
    "filtered_visits['Duration_seconds'] = filtered_visits['Duration'].dt.total_seconds()\n",
    "\n",
    "# Now you can calculate the standard deviation of the 'Duration_seconds' column\n",
    "std_duration_seconds = filtered_visits['Duration_seconds'].std()\n",
    "\n",
    "# If you prefer the standard deviation in hours, you can convert the seconds to hours first\n",
    "filtered_visits['Duration_hours'] = filtered_visits['Duration_seconds'] / 3600\n",
    "std_duration_hours = filtered_visits['Duration_hours'].std()\n",
    "\n",
    "print(f\"Standard Deviation of Duration in Seconds: {std_duration_seconds} seconds\")\n",
    "print(f\"Standard Deviation of Duration in Hours: {std_duration_hours} hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af972c9-4cbd-4d52-8347-95884f1fc8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c71c5-e7db-43d9-a98d-442c941ef6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean duration for each VISIT_ID\n",
    "mean_duration_hours_per_visit = filtered_visits.groupby('VISIT_ID')['Duration_hours'].mean()\n",
    "\n",
    "# Calculate the overall mean from the mean durations per VISIT_ID\n",
    "overall_mean_duration_hours = mean_duration_hours_per_visit.mean()\n",
    "overall_mean_duration_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a04b88-d974-48a0-955e-614df80d5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sort by VISIT_ID and Start_Time to ensure the sequence\n",
    "sorted_visits = filtered_visits.sort_values(by=['VISIT_ID', 'Start_Time'])\n",
    "\n",
    "# Calculate the actual duration for each activity\n",
    "#  Duration or calculated as difference between Start_Time and End_Time\n",
    "sorted_visits['Activity_Duration'] = (sorted_visits['End_Time'] - sorted_visits['Start_Time']).dt.total_seconds() / 3600.0\n",
    "\n",
    "#  the transition duration between the end of one activity and the start of the next\n",
    "sorted_visits['Next_Start_Time'] = sorted_visits.groupby('VISIT_ID')['Start_Time'].shift(-1)\n",
    "sorted_visits['Step_Duration'] = (sorted_visits['Next_Start_Time'] - sorted_visits['End_Time']).dt.total_seconds() / 3600.0\n",
    "\n",
    "#  calculate the standard deviation for each Activity's own duration\n",
    "std_activity_durations = sorted_visits.groupby('Activity')['Activity_Duration'].std()\n",
    "\n",
    "mean_activity_durations = sorted_visits.groupby('Activity')['Activity_Duration'].mean()\n",
    "\n",
    "# the standard deviation for the transitions between activities\n",
    "std_step_durations = sorted_visits.groupby('Activity')['Step_Duration'].std()\n",
    "\n",
    "std_activity_durations, mean_activity_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5180126-b858-4c83-858a-c58485703b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique durations for the 'Assessment' activity\n",
    "assessment_durations = filtered_visits[filtered_visits['Activity'] == 'Assessment']['Duration_hours']\n",
    "unique_assessment_durations = assessment_durations.unique()\n",
    "\n",
    "# Get basic statistics for the 'Assessment' activity to understand its distribution\n",
    "assessment_durations_stats = assessment_durations.describe()\n",
    "\n",
    "unique_assessment_durations, assessment_durations_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d965e01-85e1-4460-b96f-a03746772e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_visits_dur['VISIT_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066347bf-17d0-4a28-9ca8-6cef966f8d02",
   "metadata": {},
   "source": [
    "## Creating single row dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8078f04-8b83-461c-8eb9-cb608bfbf3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_visits_dur.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746d18d-eeb5-4ee7-b053-753d0fe23ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Determine the earliest 'Start_Time' for each 'VISIT_ID'\n",
    "earliest_times = clean_df_visits.groupby('VISIT_ID')['Start_Time'].min().reset_index()\n",
    "earliest_times.rename(columns={'Start_Time': 'First_Start_Time'}, inplace=True)\n",
    "\n",
    "# Define a function to categorize 'First_Start_Time' into the time ranges we discussed\n",
    "def categorize_time_of_day(time):\n",
    "    if time.hour < 8:\n",
    "        return 'Early Morning to Morning'\n",
    "    elif 8 <= time.hour < 16:\n",
    "        return 'Late Morning to Late Afternoon'\n",
    "    else:  # From 16:00 until midnight\n",
    "        return 'Evening to Night'\n",
    "\n",
    "# Apply the function to categorize each 'First_Start_Time'\n",
    "earliest_times['TIME_OF_THE_DAY'] = earliest_times['First_Start_Time'].apply(categorize_time_of_day)\n",
    "\n",
    "# Merge the 'TIME_OF_THE_DAY' back into the original DataFrame\n",
    "df_visits_dur_hours = clean_df_visits_dur.merge(earliest_times[['VISIT_ID', 'TIME_OF_THE_DAY']], on='VISIT_ID', how='left')\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(df_visits_dur_hours.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96e1f5-bce3-409d-a27a-805bd5e8cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits_dur_hours.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adab852-0f27-4e25-a3bf-8343c75d241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits_dur_hours.to_csv('df_visits_dur_timeofday-singlerow.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779595ee-8f23-4ade-b6c6-70dc73e74fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits_dur_hours.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81abee69-a8ad-43e0-9036-7df6a834ac26",
   "metadata": {},
   "source": [
    "## RANDOMLY ORDERING SAME TIME ACTIVITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac790f00-364a-449e-b182-90e2d6cea3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits_dur_hours.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee6965-a6ef-4936-9d14-efb4dd1c040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by VISIT_ID and Start_Time and count occurrences\n",
    "duplicate_groups = df_visits_dur_hours.groupby(['VISIT_ID', 'Start_Time']).size()\n",
    "\n",
    "# Filter groups where the count is greater than 1\n",
    "duplicate_groups = duplicate_groups[duplicate_groups > 1]\n",
    "\n",
    "# Display the duplicate groups, if any\n",
    "if not duplicate_groups.empty:\n",
    "    print(\"There are still groups with the same Start_Time within the same VISIT_ID:\")\n",
    "    print(duplicate_groups)\n",
    "else:\n",
    "    print(\"No groups with the same Start_Time within the same VISIT_ID found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b4709-6e0b-4fc7-a7f8-cdb599766042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe to ensure proper ordering\n",
    "df_visits_dur_hours_sorted = df_visits_dur_hours.sort_values(by=['VISIT_ID', 'Start_Time'])\n",
    "\n",
    "# Create a mask to identify rows with the same VISIT_ID and Start_Time\n",
    "mask = df_visits_dur_hours_sorted.duplicated(subset=['VISIT_ID', 'Start_Time'], keep=False)\n",
    "\n",
    "# Group by VISIT_ID and Start_Time and get group indices\n",
    "group_indices = df_visits_dur_hours_sorted[mask].groupby(['VISIT_ID', 'Start_Time']).ngroup()\n",
    "\n",
    "# Create random offsets within each group\n",
    "df_visits_dur_hours_sorted.loc[mask, 'Random_Offset'] = group_indices.groupby(group_indices).cumcount() + 1\n",
    "\n",
    "# Apply the offsets to Start_Time\n",
    "df_visits_dur_hours_sorted.loc[mask, 'Start_Time'] += pd.to_timedelta(df_visits_dur_hours_sorted['Random_Offset'].fillna(0), unit='s')\n",
    "\n",
    "# Drop the temporary Random_Offset column\n",
    "df_visits_dur_hours_sorted = df_visits_dur_hours_sorted.drop(columns=['Random_Offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d237e-5f2d-4331-9636-6eca1ed95109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by VISIT_ID and Start_Time and count occurrences\n",
    "duplicate_groups = df_visits_dur_hours_sorted.groupby(['VISIT_ID', 'Start_Time']).size()\n",
    "\n",
    "# Filter groups where the count is greater than 1\n",
    "duplicate_groups = duplicate_groups[duplicate_groups > 1]\n",
    "\n",
    "# Display the duplicate groups, if any\n",
    "if not duplicate_groups.empty:\n",
    "    print(\"There are still groups with the same Start_Time within the same VISIT_ID:\")\n",
    "    print(duplicate_groups)\n",
    "else:\n",
    "    print(\"No groups with the same Start_Time within the same VISIT_ID found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e2731-0b7f-4216-9105-16b7a190db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits_dur_hours_sorted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9cf91-c1b6-4dbf-960a-62c75d40fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits_dur_hours_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f138adeb-fd64-49e8-8303-9cc571885afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits_dur_hours_sorted.to_csv('df_visits_dur_timeofday-randomorder.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
